### Hinge Loss based CNN.

- CNN has state of the art results in comparison to the hand coded methods like Bayesian classifiers, boosting, tree classifiers and support vector machines.
- CNN uses millions of paramters, which are difficult to train compared to flat models. Commonly used method for training in Stochastic Gradient Descent(SGD). 
- A new method is proposed Hingle Loss Stochastic Gradient Descent (HLSGD), which results in faster training and state of the art result.
- Desribes on various components of network: input layer size, output layers size, relation to tradition feature extractors.
- Layer definition including max pooling layers, normalization layers, non linear layer.
For Non linear layer importance of rectification.
- Max pooling vs average pooling vs L2 pooling. Advantages and disadvantages.
- 